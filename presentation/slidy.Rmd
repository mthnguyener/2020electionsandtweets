---
title: "2020 Elections and Tweets"
author: "Aliya Alimujiang and Minh Nguyen"
date: ""
output: slidy_presentation
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(shiny)
library(tidyverse)
library(ggplot2)
library(shinythemes) # "superhero"

full.set <- read.csv("../data/sent_training.csv")
```

## Background

Several works have shown the potential of online social media, in particular platforms like Twitter, for analyzing the public sentiment in general has a high impact on predictions. With the increasing importance of Twitter in political discussions, a considerable number of studies also investigated the possibility to analyze political processes and predict political elections from data collected on Twitter.

For our analysis, we will be using twitter data directly scrapped from twitter using R. The daily tweets are from the following hashtags: biden2020, BidenHarris2020, trump2020,MAGA, vote. The goal is to classify the content of the tweets into Trump, Biden based on the tags as well as sentiments: immigration, economy, stimulus, tax, covid ,fake news ,racist, environment, Russia, security, etc.

By classifying at the tweet level, we can correctly take into account the difference of activity of supporters to extract the percentage of users in favor of each candidate/party. This approach allows us to correctly interpret the Twitter opinion trend as the result of the variations in engagement of the supporters of each campaign and to gain unique insight on the dynamics and structure of the social network of Twitter users in relation to their political opinion.

The goal of this analysis is to be able to predict the election results solely based on twitter data to figure out the impact of twitter as well as the prediction accuracy. We will be comparing our results with the real election results at the end to conclude and verify the role that twitter plays in terms of election.

## Data Mining and Processing

70 training / 30 testing

Sentiments Analysis

Live data from twitter extracted on 10/18/2020. We will be extracting data for a week for our training set. We will use another week of extracts as our test set.

We will be first doing descriptive analytics to analyze as well as visualize the dataset. Look for correlations and if there are any violations. We will also be using variable selection process to decide which variables to keep in our final model. We will also be doing model selection process.

So far, we have collected 2 days of data from twitter. We have done a preliminary data cleanup work in R and ran some basic analysis. Based on this it looks like Biden is getting more retweets and favorites.

## Variable Selections

```{r}
shinyApp(
  ui = fluidPage(
    theme = shinytheme("superhero"),
    wellPanel(titlePanel("Method Summary")),
    sidebarLayout(
      sidebarPanel(
        selectInput("methods", "Which Variable Method?", choices = c("method 1", "method 2", "method 3"), selected = "method 1"),
        sliderInput("mean", label = "Mean",
                    min = 0,
                    max = 8,
                    value = 3)
        ),
      mainPanel(
        p("Conclusion: Which predictors/features should we use and how many variables?"),
        uiOutput("xlim_ui"),
        plotOutput("histogram")
        )
      )
    ),
  server = function(input, output){
    output$histogram <- renderPlot({
      if(is.null(input$xlim)){
        return()
        }
      hist(rnorm(input$no_data, mean = input$mean, sd = input$sd),
           xlim = c(-input$xlim,input$xlim))
    })

    
  }
)
```

## Model Selections

### GLM
  - test 1

### Classification Tree
  - test 2
  
### RandomForest
  - test 3
  
Conclusion: Which model? Interpretability vs Predictibility.

## Challenges

```{r}
shinyApp(
  ui = fluidPage(
    theme = shinytheme("superhero"),
    sliderInput("no_data", label = "Number of data",
                min = 1000,
                max = 5000,
                value = 1000),
    sliderInput("mean", label = "Mean",
                min = 0,
                max = 8,
                value = 3),
    sliderInput("sd", label = "Standard Deviation",
                min = 1,
                max = 10,
                value = 2),
    uiOutput("xlim_ui"),
    plotOutput("histogram")
  ),
  server = function(input, output){
    
    output$xlim_ui <- renderUI({
      
      if(is.null(input$mean)){
        return()
      }
      
      sliderInput("xlim", label = "xlim",
                  min = input$mean,
                  max = 10,
                  value = input$mean,
                  step = 1)
    })
    
    output$histogram <- renderPlot({
      if(is.null(input$xlim)){
        return()
      }
      hist(rnorm(input$no_data, mean = input$mean, sd = input$sd), xlim = c(-input$xlim,input$xlim))
    })
  }
)
```

## Conclusions

## References

